{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d53b706-65de-4013-9f36-80e262a79838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\13956300996_07e64a3dbd_n_jpg.rf.747eb918cf24d815d6d084b2bd5f41dd.jpg: 640x640 8 tulips, 109.7ms\n",
      "Speed: 5.0ms preprocess, 109.7ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\13976206001_fd1c2cbd60_jpg.rf.7cf23a763983dc2abe59d7fa243b2092.jpg: 640x640 1 tulip, 36.6ms\n",
      "Speed: 4.8ms preprocess, 36.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\14741866338_bdc8bfc8d5_n_jpg.rf.3ff58cd0bf4cc7ca69bb179728035578.jpg: 640x640 1 tulip, 36.6ms\n",
      "Speed: 5.0ms preprocess, 36.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\15054866658_c1a6223403_m_jpg.rf.3982b18f3f35abf68c9875245e854a51.jpg: 640x640 1 sunflower, 38.3ms\n",
      "Speed: 4.1ms preprocess, 38.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\15240466871_ec45b65554_m_jpg.rf.12fad53d584204d580d8776d913e6830.jpg: 640x640 1 sunflower, 33.3ms\n",
      "Speed: 5.0ms preprocess, 33.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\16525204061_9b47be3726_m_jpg.rf.7c37093fc34cd8396311ec0c4488d8f9.jpg: 640x640 1 rose, 34.4ms\n",
      "Speed: 4.0ms preprocess, 34.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\18996760154_58d3c48604_jpg.rf.37405b75d6a53e76bc1eb7bc555c1088.jpg: 640x640 1 dandelion, 33.6ms\n",
      "Speed: 4.0ms preprocess, 33.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\19508264965_d1dfb565ea_n_jpg.rf.c0312d9eb7a0fac363fa9f91c8d426b0.jpg: 640x640 1 sunflower, 32.4ms\n",
      "Speed: 5.0ms preprocess, 32.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\19693717158_af4afcffd2_n_jpg.rf.5f03d5ac9ec8484ddb87dbc32039fbfd.jpg: 640x640 1 tulip, 32.7ms\n",
      "Speed: 6.0ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\20742669999_53de71a4c9_n_jpg.rf.c21639a8f9793749f9d86cdfce4ddb3b.jpg: 640x640 3 tulips, 32.0ms\n",
      "Speed: 6.0ms preprocess, 32.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\21346056089_e6f8074e5f_m_jpg.rf.33f6a6ef25dd5e0f850fced8f0165f18.jpg: 640x640 1 rose, 32.1ms\n",
      "Speed: 5.0ms preprocess, 32.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\2141413229_3f0425f972_n_jpg.rf.1399420a5c81f9c522a0be26be6fa60b.jpg: 640x640 1 rose, 56.6ms\n",
      "Speed: 4.0ms preprocess, 56.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\22274701614_901606ee34_n_jpg.rf.25331064659dc8423f0815f56df52c9a.jpg: 640x640 1 dandelion, 32.3ms\n",
      "Speed: 4.0ms preprocess, 32.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\2479491210_98e41c4e7d_m_jpg.rf.b3c84a61a03ea7e1919a3b62f1412200.jpg: 640x640 1 dandelion, 32.8ms\n",
      "Speed: 5.0ms preprocess, 32.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\26004221274_74900d17e1_n_jpg.rf.930d1a2bfc4dfa4164a0a917593cb4f8.jpg: 640x640 1 dandelion, 32.5ms\n",
      "Speed: 5.0ms preprocess, 32.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\2834890466_1cf220fba1_jpg.rf.3b555e832ee4298a211a7b82e518a8aa.jpg: 640x640 3 tulips, 32.4ms\n",
      "Speed: 4.0ms preprocess, 32.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\33890085903_0e10553b27_n_jpg.rf.874b1eb0c8889ee08d697af3ba2e3760.jpg: 640x640 1 dandelion, 32.3ms\n",
      "Speed: 5.0ms preprocess, 32.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\3451637528_b245144675_n_jpg.rf.5d0acf9580129202ad3d8973e445311b.jpg: 640x640 2 dandelions, 32.2ms\n",
      "Speed: 5.0ms preprocess, 32.2ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\4669117051_ce61e91b76_jpg.rf.bf460037da2d4a4b5d57699e978ae330.jpg: 640x640 2 daisys, 32.0ms\n",
      "Speed: 3.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\5182167964_9d1a0be0b8_n_jpg.rf.391f48a15d22180f20d6180f6d36caff.jpg: 640x640 1 rose, 1 tulip, 31.9ms\n",
      "Speed: 5.0ms preprocess, 31.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\6207492986_0ff91f3296_jpg.rf.4e2860ada2cbe8e93ad6cdc706babe83.jpg: 640x640 1 daisy, 1 sunflower, 32.1ms\n",
      "Speed: 3.9ms preprocess, 32.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\6596277835_9f86da54bb_jpg.rf.3c42b68ea8ff797e35d3bc38a0a22f23.jpg: 640x640 1 daisy, 51.1ms\n",
      "Speed: 4.0ms preprocess, 51.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\6867597533_d65d1c39fb_n_jpg.rf.59d03e42ad23f3d2a86b05da91447e02.jpg: 640x640 1 rose, 32.9ms\n",
      "Speed: 4.0ms preprocess, 32.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Object_detection\\dataset\\test\\images\\7376473742_532364cee5_n_jpg.rf.abe5562e4b5a93d09b6dad8e99461f39.jpg: 640x640 1 rose, 31.1ms\n",
      "Speed: 5.1ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "model_weights_path = 'E:/Object_detection/runs/detect/train/weights/best.pt'\n",
    "input_dir = Path('E:/Object_detection/dataset/test/images')\n",
    "\n",
    "\n",
    "model = YOLO(model_weights_path)\n",
    "\n",
    "\n",
    "for img in input_dir.iterdir():\n",
    "    results = model(img, save=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56577faa-bbb7-4342-ad27-43e5172c51c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
